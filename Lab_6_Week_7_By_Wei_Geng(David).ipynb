{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab #6 - Week #7 By Wei Geng(David).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "njRBvvtbZcEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Class IT-533 Week #7  - Measures of Association\n",
        "# Summer 2020\n",
        "# Lab #6 - ramen-ratings.csv\n",
        "# By Wei Geng(David) and Anusha Bale\n",
        "# Created on: 06/28/2020\n",
        "# Honor Code: “I have neither given or received, nor have I tolerated others' use of unauthorized aid.”"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8npOXrx7gRIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install pandas in case you dont have pandas, matplotlib and sklearn pre-installed\n",
        "%pip install pandas\n",
        "%pip install matplotlib\n",
        "%pip sklearn"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Vgck51GZlu7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "d810690d-71fe-41c4-c181-70dc1cccbc35"
      },
      "source": [
        "# Convert to pandas DataFrame\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "remen_df = pd.read_csv('https://raw.githubusercontent.com/intelspeedstep/AMOD533/master/ramen-ratings.csv')\n",
        "remen_df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review #</th>\n",
              "      <th>Brand</th>\n",
              "      <th>Variety</th>\n",
              "      <th>Style</th>\n",
              "      <th>Country</th>\n",
              "      <th>Stars</th>\n",
              "      <th>Top Ten</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2580</td>\n",
              "      <td>New Touch</td>\n",
              "      <td>T's Restaurant Tantanmen</td>\n",
              "      <td>Cup</td>\n",
              "      <td>Japan</td>\n",
              "      <td>3.75</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2579</td>\n",
              "      <td>Just Way</td>\n",
              "      <td>Noodles Spicy Hot Sesame Spicy Hot Sesame Guan...</td>\n",
              "      <td>Pack</td>\n",
              "      <td>Taiwan</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2578</td>\n",
              "      <td>Nissin</td>\n",
              "      <td>Cup Noodles Chicken Vegetable</td>\n",
              "      <td>Cup</td>\n",
              "      <td>USA</td>\n",
              "      <td>2.25</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2577</td>\n",
              "      <td>Wei Lih</td>\n",
              "      <td>GGE Ramen Snack Tomato Flavor</td>\n",
              "      <td>Pack</td>\n",
              "      <td>Taiwan</td>\n",
              "      <td>2.75</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2576</td>\n",
              "      <td>Ching's Secret</td>\n",
              "      <td>Singapore Curry</td>\n",
              "      <td>Pack</td>\n",
              "      <td>India</td>\n",
              "      <td>3.75</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Review #           Brand  ... Stars Top Ten\n",
              "0      2580       New Touch  ...  3.75     NaN\n",
              "1      2579        Just Way  ...     1     NaN\n",
              "2      2578          Nissin  ...  2.25     NaN\n",
              "3      2577         Wei Lih  ...  2.75     NaN\n",
              "4      2576  Ching's Secret  ...  3.75     NaN\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNe34DsGEsSt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "5814224e-48db-49f9-8c5c-4eaf6ca3b33a"
      },
      "source": [
        "# output the data attributes and its datatypes, plus the shape of the dataset\n",
        "print(remen_df.info(verbose=True))\n",
        "print(remen_df.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2580 entries, 0 to 2579\n",
            "Data columns (total 7 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Review #  2580 non-null   int64 \n",
            " 1   Brand     2580 non-null   object\n",
            " 2   Variety   2580 non-null   object\n",
            " 3   Style     2578 non-null   object\n",
            " 4   Country   2580 non-null   object\n",
            " 5   Stars     2580 non-null   object\n",
            " 6   Top Ten   41 non-null     object\n",
            "dtypes: int64(1), object(6)\n",
            "memory usage: 141.2+ KB\n",
            "None\n",
            "(2580, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7-FWME7wXq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert Stars from object to numberic and Review # to str since ID number usually has no analytical value\n",
        "remen_df.loc[remen_df[\"Stars\"]=='Unrated','Stars']=np.nan\n",
        "remen_df['Stars']=remen_df['Stars'].astype(float)\n",
        "remen_df['Review #']=remen_df['Review #'].astype(str)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X4BF5cCEmE-",
        "colab_type": "text"
      },
      "source": [
        "### <font color = 'orange'> Model #1: Run my team dataset with Decision Tree and optimize the configuration for model comparisons</font>\n",
        "</font></br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29mgbebnfXOu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "fdc8b6b3-850e-40dc-aeec-db47c3434788"
      },
      "source": [
        "# Convert the string variables to numeric categorical varibles, so the model can run. Sklearn classifers requires categorical variables to be numerically coded.\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "remen_df[\"Brand\"] = LabelEncoder().fit_transform(remen_df[\"Brand\"])\n",
        "remen_df[\"Variety\"] = LabelEncoder().fit_transform(remen_df[\"Variety\"])\n",
        "remen_df[\"Style\"] = LabelEncoder().fit_transform(remen_df[\"Style\"].astype(str))\n",
        "remen_df[\"Country\"] = LabelEncoder().fit_transform(remen_df[\"Country\"])\n",
        "remen_df[\"Top Ten\"] = LabelEncoder().fit_transform(remen_df[\"Top Ten\"].astype(str))\n",
        "remen_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review #</th>\n",
              "      <th>Brand</th>\n",
              "      <th>Variety</th>\n",
              "      <th>Style</th>\n",
              "      <th>Country</th>\n",
              "      <th>Stars</th>\n",
              "      <th>Top Ten</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2580</td>\n",
              "      <td>190</td>\n",
              "      <td>2189</td>\n",
              "      <td>4</td>\n",
              "      <td>18</td>\n",
              "      <td>3.75</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2579</td>\n",
              "      <td>119</td>\n",
              "      <td>1443</td>\n",
              "      <td>5</td>\n",
              "      <td>32</td>\n",
              "      <td>1.00</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2578</td>\n",
              "      <td>192</td>\n",
              "      <td>454</td>\n",
              "      <td>4</td>\n",
              "      <td>35</td>\n",
              "      <td>2.25</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2577</td>\n",
              "      <td>336</td>\n",
              "      <td>709</td>\n",
              "      <td>5</td>\n",
              "      <td>32</td>\n",
              "      <td>2.75</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2576</td>\n",
              "      <td>38</td>\n",
              "      <td>1954</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "      <td>3.75</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Review #  Brand  Variety  Style  Country  Stars  Top Ten\n",
              "0     2580    190     2189      4       18   3.75       38\n",
              "1     2579    119     1443      5       32   1.00       38\n",
              "2     2578    192      454      4       35   2.25       38\n",
              "3     2577    336      709      5       32   2.75       38\n",
              "4     2576     38     1954      5       16   3.75       38"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWmuOf2td4Dd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "outputId": "e39fc249-7bf6-4fa6-c497-b2192c04e65a"
      },
      "source": [
        "# 1) Decision Tree can handle both continuous or binary variables, So, I decided to make 'Stars' as a binary target variable, which I need to convert it first from \n",
        "# continuous to binary. This is supervised learning for classification problem.\n",
        "# 2) Note that Multicolinearity doesnt negatively impact any tree based algorithm, such as decision tree or random forest since these algorithms are not linear model. \n",
        "# so, we only need drop the ID variable. \n",
        "# 3) split dataset into training and testing with ratio of 70% to 30%.\n",
        "# 4) Fit the model with all variables in X, and select depth of tree to 6. If depth is a small number, the model is likily to be  stable, but if dept is a big number, it could be more overfitting.\n",
        "# I pick 6 this time. I think this is a reasonable number, not too big nor too small. Meanwhile, I contro the mininmum sample leaf to 50. Again, if you set the leaf too\n",
        "# small, there is a risk of overfitting. I think 50 is a good number.\n",
        "# 5) After running the model, we get model accuracy equal to 78% on training and 76% on the test dataset. This is a pretty good model.\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "remen_df.loc[remen_df['Stars']>3,'Stars_Ind']=1\n",
        "remen_df['Stars_Ind'].fillna(0,inplace=True)\n",
        "X=remen_df.drop(['Stars','Stars_Ind','Review #'], axis=1)\n",
        "y=remen_df['Stars_Ind']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1859, test_size=0.3)\n",
        "tree = DecisionTreeClassifier(max_depth=6,  min_samples_leaf=50, random_state=1859)\n",
        "tree.fit(X_train, y_train)\n",
        "y_pred = tree.predict(X_test)\n",
        "print(\"Test set predictions:\\n\", y_pred)\n",
        "print(\"Training set score: {:.2f}\".format(tree.score(X_train, y_train)))\n",
        "print(\"Test set score: {:.2f}\".format(tree.score(X_test, y_test)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set predictions:\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1.]\n",
            "Training set score: 0.78\n",
            "Test set score: 0.76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTw0gLZgft9k",
        "colab_type": "text"
      },
      "source": [
        "### <font color = 'orange'> Model #2: Run my team dataset with Random Forest and optimize the configuration for model comparisons</font>\n",
        "</font></br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LoRwjSPf9Ew",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "outputId": "8377f4d5-0031-4f89-9436-4e1d535469c5"
      },
      "source": [
        "# 1) Random Forest is a probability tree algorthm which uses the ensemble method to build multiple number of decision trees to average out the performance\n",
        "# This would give us a very stable model, however, it is not difficult to explain the which features are important in which model.\n",
        "# 2) Again, Random Forest can handle both continuous and categorical target variable , \n",
        "# so we set 'Stars' as a binary target variable, and split data with hold-out methold with 70% to 30%. \n",
        "# 3) we also set n_estimator to 100, this means we would split dataset into 30 pieces and build 100 different trees. \n",
        "# 4) After running the model, we get model accuracy equal to 78% on the training set and 73% on test set. This is a very good model, but the model \n",
        "# generalization is not as good  as the decision tree. To solve this, we canto use some techiques in auto-tuning the model to find the best parameter values \n",
        "# that can optimize model, This is another machine learning topic. \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "X=remen_df.drop(['Stars','Stars_Ind','Review #'], axis=1)\n",
        "y=remen_df['Stars_Ind']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1859, test_size=0.3)\n",
        "forest = RandomForestClassifier(n_estimators=100, random_state=1859)\n",
        "forest.fit(X_train, y_train)\n",
        "y_pred = forest.predict(X_test)\n",
        "print(\"Test set predictions:\\n\", y_pred)\n",
        "print(\"Training set score: {:.2f}\".format(tree.score(X_train, y_train)))\n",
        "print(\"Test set score: {:.2f}\".format(forest.score(X_test, y_test)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set predictions:\n",
            " [0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1.\n",
            " 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1.\n",
            " 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1.\n",
            " 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
            " 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
            " 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1.]\n",
            "Training set score: 0.78\n",
            "Test set score: 0.73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "shAoI-OHdI_L"
      },
      "source": [
        "### <font color = 'orange'>model #3: Run my team dataset with K-Nearest Neighbors model, and optimize the configuration for model comparisons. This was done from the previous lab.</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTKmVYoz63Zu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "outputId": "66f52b87-7347-4a7a-8dea-5375964d2442"
      },
      "source": [
        "# 1) KNN handles binary variables, so, I first convert 'Stars' to a binary value by set value greater than 3 equal to 1, else to 0.\n",
        "# This 'Stars_Ind' become my target variable. Again, this is supervised learning for classification problem.\n",
        "# 2) No need to check correlation ahead or drop any variables since KNN is not linear model\n",
        "# 3) split dataset into training and testing with ratio of 70% to 30%.\n",
        "# 4) Fit the model with all variables in X, and select n to 5. If n is a small number, the model is less stable, but if n is a big number, it would be more errors.\n",
        "# so, I manually tune the model to pick 5 as the value for n. If you pick 4 or 6, the model accuracy would decline.\n",
        "# 5) After running the model, we get model accuracy equal to 72% on test dataset. This is a pretty good model. \n",
        "# However, there is concern on overfitting since the model as much better performance on the training dataset -- 81%.\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "X=remen_df.drop(['Stars','Stars_Ind','Review #'], axis=1)\n",
        "y=remen_df['Stars_Ind']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1859, test_size=0.3)\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "print(\"Test set predictions:\\n\", y_pred)\n",
        "print(\"Training set score: {:.2f}\".format(knn.score(X_train, y_train)))\n",
        "print(\"Test set score: {:.2f}\".format(knn.score(X_test, y_test)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set predictions:\n",
            " [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
            " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
            " 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
            " 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0.\n",
            " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0.\n",
            " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1.]\n",
            "Training set score: 0.82\n",
            "Test set score: 0.71\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfIAggh0H8kb",
        "colab_type": "text"
      },
      "source": [
        "### <font color = 'orange'>Model #4: Run my team dataset with Naive Bayes model, and optimize the configuration for model comparisons. This was done from the previous lab.  </font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8xrRl9zlSE0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "outputId": "3358faf6-b5ae-4746-e9aa-5682ae7ee9de"
      },
      "source": [
        "# 1) Naive Bayes handles binary and categorical dependent variable well if predictors are independent\n",
        "# 2) Again, we set 'Stars_Ind' as a binary target variable, and split data with hold-out methold with 70% to 30%\n",
        "# 3) There are 3 types of naive bayes models --  Binomial, multimial and Guassian, and we use them based on the following rules,\n",
        "# In the case of predictors are categorical variables, such as counts or labels, a multinomial distribution can be used. \n",
        "# If the variables are binary, such as yes/no or true/false, a binomial distribution can be used. \n",
        "# If a variable is numerical, such as a measurement, often a Gaussian distribution is used. \n",
        "# 4) I choose to use Gaussian distribution since the predictors are numerical.\n",
        "# 5) After running the model, we get model accuracy equal to 74% on test dataset (we are predicting yes or no, we switch the label of target variable by (1-0.24))\n",
        "# Moreover, the performance on the training dataset is 76%. This indicates it is a very stable model.\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "remen_df.loc[remen_df['Stars']>3,'Stars_Ind']=1\n",
        "remen_df['Stars_Ind'].fillna(0,inplace=True)\n",
        "X=remen_df.drop(['Stars','Stars_Ind','Review #'], axis=1)\n",
        "y=remen_df['Stars_Ind']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1859, test_size=0.3)\n",
        "GNB = GaussianNB()\n",
        "GNB.fit(X_train,y_train)\n",
        "y_pred = GNB.predict(X_test)\n",
        "print(\"Test set predictions:\\n\", y_pred)\n",
        "print(\"Training set score: {:.2f}\".format(1-GNB.score(X_train, y_train)))\n",
        "print(\"Test set score: {:.2f}\".format(1-GNB.score(X_test, y_test)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set predictions:\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0.]\n",
            "Training set score: 0.76\n",
            "Test set score: 0.74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ebbk8IXFpbS",
        "colab_type": "text"
      },
      "source": [
        "**Note: Please check the attached Word Document for the answers for this week's lab assignment questions. Thanks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rL4-iAvkiWpN",
        "colab_type": "text"
      },
      "source": [
        "### <font color = 'orange'>------------------------------------------------------------------------END--------------------------------------------------------------------------------- </font>"
      ]
    }
  ]
}